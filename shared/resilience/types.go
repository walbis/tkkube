package resilience

import (
	"sync"
	"time"
)

// EventType represents different types of circuit breaker events
type EventType string

const (
	EventStateChange    EventType = "state_change"
	EventFailure        EventType = "failure"
	EventSuccess        EventType = "success"
	EventRecovery       EventType = "recovery"
	EventReset          EventType = "reset"
	EventAlert          EventType = "alert"
	EventHealthCheck    EventType = "health_check"
)

// CircuitBreakerEvent represents an event in the circuit breaker lifecycle
type CircuitBreakerEvent struct {
	Type            EventType            `json:"type"`
	CircuitBreaker  string               `json:"circuit_breaker"`
	Timestamp       time.Time            `json:"timestamp"`
	Message         string               `json:"message"`
	FromState       CircuitBreakerState  `json:"from_state,omitempty"`
	ToState         CircuitBreakerState  `json:"to_state,omitempty"`
	Error           string               `json:"error,omitempty"`
	Metadata        map[string]interface{} `json:"metadata,omitempty"`
}

// SystemHealthReport represents overall system health based on circuit breakers
type SystemHealthReport struct {
	Timestamp            time.Time                   `json:"timestamp"`
	OverallStatus        string                      `json:"overall_status"`        // healthy, degraded, unhealthy
	OverallHealthScore   float64                     `json:"overall_health_score"`  // 0-100
	TotalCircuitBreakers int                         `json:"total_circuit_breakers"`
	HealthyServices      int                         `json:"healthy_services"`
	DegradedServices     int                         `json:"degraded_services"`
	UnhealthyServices    int                         `json:"unhealthy_services"`
	Services             map[string]*ServiceHealth   `json:"services"`
}

// ServiceHealth represents health information for a specific service
type ServiceHealth struct {
	Name            string              `json:"name"`
	State           CircuitBreakerState `json:"state"`
	Healthy         bool                `json:"healthy"`
	TotalRequests   int64               `json:"total_requests"`
	SuccessRate     float64             `json:"success_rate"`
	FailureStreak   int64               `json:"failure_streak"`
	LastFailure     time.Time           `json:"last_failure"`
	LastStateChange time.Time           `json:"last_state_change"`
}

// DetailedMetrics provides comprehensive metrics for a circuit breaker
type DetailedMetrics struct {
	CircuitBreakerName string              `json:"circuit_breaker_name"`
	State              CircuitBreakerState `json:"state"`
	Timestamp          time.Time           `json:"timestamp"`
	
	// Request metrics
	TotalRequests    int64 `json:"total_requests"`
	SuccessfulReqs   int64 `json:"successful_requests"`
	FailedReqs       int64 `json:"failed_requests"`
	RejectedReqs     int64 `json:"rejected_requests"`
	
	// State-specific metrics
	ClosedRequests   int64 `json:"closed_requests"`
	OpenRequests     int64 `json:"open_requests"`
	HalfOpenRequests int64 `json:"half_open_requests"`
	
	// Performance metrics
	SuccessRate    float64 `json:"success_rate"`
	FailureRate    float64 `json:"failure_rate"`
	RejectionRate  float64 `json:"rejection_rate"`
	
	// Timing metrics
	FailureStreak   int64     `json:"failure_streak"`
	SuccessStreak   int64     `json:"success_streak"`
	StateChanges    int64     `json:"state_changes"`
	LastFailure     time.Time `json:"last_failure"`
	LastSuccess     time.Time `json:"last_success"`
	LastStateChange time.Time `json:"last_state_change"`
	OpenedAt        time.Time `json:"opened_at"`
	LastRecoveryAt  time.Time `json:"last_recovery_at"`
}

// AggregatedMetrics provides system-wide aggregated metrics
type AggregatedMetrics struct {
	Timestamp              time.Time `json:"timestamp"`
	TotalCircuitBreakers   int       `json:"total_circuit_breakers"`
	ClosedCircuitBreakers  int       `json:"closed_circuit_breakers"`
	OpenCircuitBreakers    int       `json:"open_circuit_breakers"`
	HalfOpenCircuitBreakers int      `json:"half_open_circuit_breakers"`
	TotalRequests          int64     `json:"total_requests"`
	TotalSuccessful        int64     `json:"total_successful"`
	TotalFailed            int64     `json:"total_failed"`
	TotalRejected          int64     `json:"total_rejected"`
	TotalStateChanges      int64     `json:"total_state_changes"`
	OverallSuccessRate     float64   `json:"overall_success_rate"`
	OverallFailureRate     float64   `json:"overall_failure_rate"`
	OverallRejectionRate   float64   `json:"overall_rejection_rate"`
	HealthPercentage       float64   `json:"health_percentage"`
}

// Alert represents an alert generated by the circuit breaker system
type Alert struct {
	ID             string    `json:"id"`
	CircuitBreaker string    `json:"circuit_breaker"`
	Type           string    `json:"type"`           // state_change, high_failure_rate, recovery, etc.
	Severity       string    `json:"severity"`       // low, medium, high, critical
	Message        string    `json:"message"`
	Timestamp      time.Time `json:"timestamp"`
	Resolved       bool      `json:"resolved"`
	ResolvedAt     time.Time `json:"resolved_at,omitempty"`
	Metadata       map[string]interface{} `json:"metadata,omitempty"`
}

// EventLogger handles logging of circuit breaker events
type EventLogger struct {
	config     *ObservabilityConfig
	events     []*CircuitBreakerEvent
	maxEvents  int
	mu         sync.RWMutex
}

// NewEventLogger creates a new event logger
func NewEventLogger(config *ObservabilityConfig) *EventLogger {
	return &EventLogger{
		config:    config,
		events:    make([]*CircuitBreakerEvent, 0),
		maxEvents: 1000, // Keep last 1000 events
	}
}

// LogEvent logs a generic event
func (el *EventLogger) LogEvent(eventType string, data map[string]interface{}) {
	if !el.config.LoggingEnabled {
		return
	}
	
	// Use standard logging for now
	// In production, this might integrate with structured logging systems
	log.Printf("Circuit Breaker Event [%s]: %v", eventType, data)
}

// RecordEvent records a circuit breaker event
func (el *EventLogger) RecordEvent(event *CircuitBreakerEvent) {
	el.mu.Lock()
	defer el.mu.Unlock()
	
	// Add event to history
	el.events = append(el.events, event)
	
	// Trim events if we exceed maximum
	if len(el.events) > el.maxEvents {
		el.events = el.events[1:]
	}
}

// GetRecentEvents returns recent events (limited by count)
func (el *EventLogger) GetRecentEvents(limit int) []*CircuitBreakerEvent {
	el.mu.RLock()
	defer el.mu.RUnlock()
	
	if limit <= 0 || limit > len(el.events) {
		limit = len(el.events)
	}
	
	// Return most recent events
	start := len(el.events) - limit
	result := make([]*CircuitBreakerEvent, limit)
	copy(result, el.events[start:])
	
	return result
}

// AlertManager handles alert generation and management
type AlertManager struct {
	config       *ObservabilityConfig
	activeAlerts map[string]*Alert
	alertHistory []*Alert
	lastAlerts   map[string]time.Time // Circuit breaker -> last alert time
	maxHistory   int
	mu           sync.RWMutex
}

// NewAlertManager creates a new alert manager
func NewAlertManager(config *ObservabilityConfig) *AlertManager {
	return &AlertManager{
		config:       config,
		activeAlerts: make(map[string]*Alert),
		alertHistory: make([]*Alert, 0),
		lastAlerts:   make(map[string]time.Time),
		maxHistory:   500, // Keep last 500 alerts
	}
}

// CheckForAlert checks if an alert should be generated for a state change
func (am *AlertManager) CheckForAlert(circuitBreakerName string, from, to CircuitBreakerState) {
	if !am.config.AlertingEnabled {
		return
	}
	
	now := time.Now()
	
	// Check cooldown
	if lastAlert, exists := am.lastAlerts[circuitBreakerName]; exists {
		if now.Sub(lastAlert) < am.config.AlertCooldown {
			return // Still in cooldown
		}
	}
	
	var alert *Alert
	
	switch to {
	case StateOpen:
		alert = &Alert{
			ID:             fmt.Sprintf("%s-open-%d", circuitBreakerName, now.Unix()),
			CircuitBreaker: circuitBreakerName,
			Type:           "circuit_open",
			Severity:       "high",
			Message:        fmt.Sprintf("Circuit breaker '%s' has opened due to failures", circuitBreakerName),
			Timestamp:      now,
			Metadata: map[string]interface{}{
				"from_state": from.String(),
				"to_state":   to.String(),
			},
		}
	case StateClosed:
		if from == StateOpen || from == StateHalfOpen {
			alert = &Alert{
				ID:             fmt.Sprintf("%s-recovered-%d", circuitBreakerName, now.Unix()),
				CircuitBreaker: circuitBreakerName,
				Type:           "circuit_recovered",
				Severity:       "medium",
				Message:        fmt.Sprintf("Circuit breaker '%s' has recovered and closed", circuitBreakerName),
				Timestamp:      now,
				Metadata: map[string]interface{}{
					"from_state": from.String(),
					"to_state":   to.String(),
				},
			}
		}
	case StateHalfOpen:
		alert = &Alert{
			ID:             fmt.Sprintf("%s-halfopen-%d", circuitBreakerName, now.Unix()),
			CircuitBreaker: circuitBreakerName,
			Type:           "circuit_half_open",
			Severity:       "medium",
			Message:        fmt.Sprintf("Circuit breaker '%s' is attempting recovery (half-open)", circuitBreakerName),
			Timestamp:      now,
			Metadata: map[string]interface{}{
				"from_state": from.String(),
				"to_state":   to.String(),
			},
		}
	}
	
	if alert != nil {
		am.addAlert(alert)
		am.lastAlerts[circuitBreakerName] = now
	}
}

// addAlert adds an alert to the manager
func (am *AlertManager) addAlert(alert *Alert) {
	am.mu.Lock()
	defer am.mu.Unlock()
	
	// Add to active alerts
	am.activeAlerts[alert.ID] = alert
	
	// Add to history
	am.alertHistory = append(am.alertHistory, alert)
	
	// Trim history if needed
	if len(am.alertHistory) > am.maxHistory {
		am.alertHistory = am.alertHistory[1:]
	}
}

// GetActiveAlerts returns currently active alerts
func (am *AlertManager) GetActiveAlerts() []*Alert {
	am.mu.RLock()
	defer am.mu.RUnlock()
	
	alerts := make([]*Alert, 0, len(am.activeAlerts))
	for _, alert := range am.activeAlerts {
		alerts = append(alerts, alert)
	}
	
	return alerts
}

// ProcessAlerts processes and returns new alerts
func (am *AlertManager) ProcessAlerts() []*Alert {
	am.mu.RLock()
	defer am.mu.RUnlock()
	
	// For now, just return active alerts
	// In a more sophisticated implementation, this would:
	// - Send notifications
	// - Auto-resolve old alerts
	// - Escalate critical alerts
	
	return am.GetActiveAlerts()
}

// ResolveAlert marks an alert as resolved
func (am *AlertManager) ResolveAlert(alertID string) {
	am.mu.Lock()
	defer am.mu.Unlock()
	
	if alert, exists := am.activeAlerts[alertID]; exists {
		alert.Resolved = true
		alert.ResolvedAt = time.Now()
		delete(am.activeAlerts, alertID)
	}
}

// HealthMonitor monitors the health of circuit breakers
type HealthMonitor struct {
	config *ObservabilityConfig
}

// NewHealthMonitor creates a new health monitor
func NewHealthMonitor(config *ObservabilityConfig) *HealthMonitor {
	return &HealthMonitor{
		config: config,
	}
}

// MetricsAggregator aggregates metrics from multiple circuit breakers
type MetricsAggregator struct {
	config     *ObservabilityConfig
	monitoring monitoring.MetricsCollector
}

// NewMetricsAggregator creates a new metrics aggregator
func NewMetricsAggregator(config *ObservabilityConfig, monitoring monitoring.MetricsCollector) *MetricsAggregator {
	return &MetricsAggregator{
		config:     config,
		monitoring: monitoring,
	}
}